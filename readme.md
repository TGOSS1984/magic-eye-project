# ğŸ‘ï¸ Magic Eye Generator

**Live demo:**  
ğŸ‘‰ https://magic-eye-project.streamlit.app/

A professional-grade **Magic Eye / autostereogram generator** that creates single-image stereograms from:

- Grayscale **depth maps**
- Ordinary **RGB photos** (via optional AI depth estimation)

The project combines classic stereogram algorithms with modern depth estimation and a polished Streamlit interface.

---

## ğŸ“š Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [How It Works](#how-it-works)
- [Project Architecture](#project-architecture)
- [Usage](#usage)
  - [Command Line Interface (CLI)](#command-line-interface-cli)
  - [Web App (Streamlit)](#web-app-streamlit)
- [AI Depth Estimation (Optional)](#ai-depth-estimation-optional)
- [Depth Debug & Inspection Tools](#depth-debug--inspection-tools)
- [Presets & Visual Tuning](#presets--visual-tuning)
- [Deployment](#deployment)
- [Testing Philosophy](#testing-philosophy)
- [Demo Assets](#demo-assets)
- [Roadmap](#roadmap)

---

## ğŸ§  Overview

Magic Eye (autostereogram) images encode 3D depth information into a **single 2D image** that the human visual system can decode without glasses.

This project builds that pipeline end-to-end:

RGB photo (optional)
â†“
Depth estimation
â†“
Depth remapping & smoothing
â†“
Stereogram constraint solver
â†“
Magic Eye image

yaml
Copy code

The system is designed to be:
- Modular
- Inspectable
- Deterministic (when desired)
- Suitable for both CLI and web use

---

## âœ¨ Key Features

- ğŸ¯ Classic random-dot and texture-based autostereograms
- ğŸ§  Optional AI depth-from-photo (MiDaS-style monocular depth)
- ğŸšï¸ Full control over depth mapping, eye separation, and smoothing
- ğŸ” Bidirectional constraint solving for wide subjects
- ğŸ–¼ï¸ Built-in texture generators (random dots, blue noise, stripes)
- ğŸ” Depth debug preview (raw â†’ remapped â†’ smoothed)
- ğŸ’¾ Exportable intermediate depth maps
- ğŸŒ Deployed Streamlit web demo

---

## âš™ï¸ How It Works

At its core, the generator:

1. **Normalises depth** into `[0, 1]`
2. **Remaps depth** using near/far planes and gamma curves
3. **Optionally smooths** noisy depth maps
4. **Applies stereogram constraints** horizontally
5. **Blends passes** (optional bidirectional mode)
6. Produces a single stereogram image

This mirrors how classic Magic Eye images were created â€” with modern tooling.

---

## ğŸ—ï¸ Project Architecture

magic-eye-project/
â”‚
â”œâ”€â”€ app/
â”‚ â””â”€â”€ streamlit_app.py # Web UI
â”‚
â”œâ”€â”€ src/
â”‚ â””â”€â”€ magic_eye/
â”‚ â”œâ”€â”€ stereogram.py # Core algorithm
â”‚ â”œâ”€â”€ depth_ai.py # AI depth estimation
â”‚ â”œâ”€â”€ depth_sculpt.py # Synthetic depth enhancement
â”‚ â”œâ”€â”€ patterns.py # Texture generators
â”‚ â””â”€â”€ cli.py # Command-line interface
â”‚
â”œâ”€â”€ examples/
â”‚ â””â”€â”€ demo_depth.png # Known-good demo depth map
â”‚
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ screenshots/ # UI screenshots (placeholder)
â”‚ â””â”€â”€ demo.gif # Demo animation (placeholder)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸš€ Usage

### Command Line Interface (CLI)

Generate a stereogram from a depth map:

```bash
pip install -e .[dev]
python -m magic_eye.cli \
  --depth path/to/depth.png \
  --out output.png
Tweak depth perception:

bash
Copy code
python -m magic_eye.cli \
  --depth depth.png \
  --out output.png \
  --eye-sep 90 \
  --max-shift 30
ğŸŒ Web App (Streamlit)
Run locally:

bash
Copy code
pip install -e .[web]
streamlit run app/streamlit_app.py
Features
Upload depth maps or RGB photos

Built-in demo depth (no uploads required)

Pattern selection

Live depth tuning

Depth debug previews

Downloadable results

ğŸ“¸ Screenshot placeholder:
docs/screenshots/streamlit_ui.png

ğŸ§  AI Depth Estimation (Optional)
AI depth estimation is optional and disabled on some deployments.

To enable locally:

bash
Copy code
pip install -e .[web,ai]
streamlit run app/streamlit_app.py
The AI pipeline:

Uses a pretrained monocular depth model

Produces relative (not metric) depth

Can be enhanced with synthetic sculpting for stereograms

ğŸ” Depth Debug & Inspection Tools
When enabled, the app displays:

Raw depth

Remapped depth

Smoothed depth

Each stage can be exported for inspection.

This makes the system transparent and educational â€” not a black box.

ğŸ›ï¸ Presets & Visual Tuning
Included presets optimise for different subject types:

Balanced (default)

Character / Portrait

Creature / Wide subject

Landscape / Scene

High detail / Noisy depth

Presets adjust:

Near / far depth planes

Gamma curves

Blur radius

Eye separation

Bidirectional passes

â˜ï¸ Deployment
This project is deployed using Streamlit Community Cloud.

Deploy your own copy
Fork this repository

Create a new app in Streamlit Community Cloud

Set the entry file to:

bash
Copy code
app/streamlit_app.py
Dependencies are installed from requirements.txt

âš ï¸ Python version is configured via Streamlit Cloud settings.

ğŸ§ª Testing Philosophy
We do not unit-test the AI model, by design:

It downloads large pretrained weights

Outputs vary across hardware

It would break deterministic CI

Instead, testing focuses on:

Core stereogram algorithms

Deterministic depth pipelines

Manual visual verification (industry standard for this domain)

This is deliberate and professional practice.

ğŸ¥ Demo Assets
Demo Depth Map
A known-good depth map is included:

bash
Copy code
examples/demo_depth.png
Used for:

Demo mode

Regression testing

Visual tuning

Demo GIF (placeholder)


To create:

Run the app locally

Record a short interaction

Save as docs/demo.gif

ğŸ›£ï¸ Roadmap
Completed
âœ… Core stereogram algorithm

âœ… CLI tool

âœ… Streamlit UI

âœ… AI depth integration

âœ… Depth debug tooling

âœ… Cloud deployment

Possible Extensions
Export side-by-side stereo pairs

Animated depth sweeps

VR-friendly output

Performance optimisations (Numba / Cython)

ğŸ“Œ Final Notes
This project is intentionally scoped to demonstrate:

Algorithmic thinking

Visual computing

Clean Python architecture

Responsible AI integration

It is designed to be understandable, extensible, and portfolio-ready.